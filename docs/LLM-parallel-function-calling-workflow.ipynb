{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f19be3f",
   "metadata": {},
   "source": [
    "# LLM parallel function calling workflow\n",
    "\n",
    "## *Gemini*\n",
    "\n",
    "Anton Antonov   \n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com)   \n",
    "June 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db6a8c",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d272d5",
   "metadata": {},
   "source": [
    "This notebook shows how to do parallel [Function Calling](https://ai.google.dev/gemini-api/docs/function-calling) workflows with Large Language Models (LLMs) of Gemini. \n",
    "\n",
    "The Raku package [\"WWW::Gemini\"](https://github.com/antononcube/Raku-WWW-Gemini), [AAp2], is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8619064",
   "metadata": {},
   "source": [
    "### Examples and big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a0e34",
   "metadata": {},
   "source": [
    "The rest of the notebook gives concrete code how to do streamline multiple-tool function calling with Gemini's LLMs using Raku. \n",
    "Gemini's function calling example [\"Parallel Function Calling\"](https://ai.google.dev/gemini-api/docs/function-calling#parallel_function_calling), [Gem1], is followed.\n",
    "\n",
    "This notebook belongs to a collection of notebooks describing how to do LLM function calling with Raku.\n",
    "\n",
    "Compared to the previously described LLM workflows with OpenAI, [[AA1](https://rakuforprediction.wordpress.com/2025/06/01/llm-function-calling-workflows-part-1-openai/)], and Gemini, [[AA2](https://rakuforprediction.wordpress.com/2025/06/07/llm-function-calling-workflows-part-2-googles-gemini/)], the Gemini LLM workflow in this notebook demonstrates:\n",
    "\n",
    "- Use of multiple tools (parallel function calling)\n",
    "- Automatic generation of hashmap (or JSON) tool descriptors\n",
    "- Streamlined computation of multiple tool results from multiple LLM requests\n",
    "\n",
    "The streamlining is achieved by using the provided by [\"LLM::Functions\"](https://raku.land/zef:antononcube/LLM::Functions), [AAp3]:\n",
    "\n",
    "- Classes `LLM::Tool`, `LLM::ToolRequest`, and `LLM::ToolResult`\n",
    "- Subs `llm-tool-definition` and `generate-llm-tool-result`\n",
    "    - The former sub leverages Raku's introspection features. \n",
    "    - The latter sub matches tools and requests in order to compute tool responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bcc90a",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe460b7",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8afa369",
   "metadata": {},
   "outputs": [],
   "source": [
    "use JSON::Fast;\n",
    "use Data::Reshapers;\n",
    "use Data::TypeSystem;\n",
    "use LLM::Tooling;\n",
    "use WWW::Gemini;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515092ec",
   "metadata": {},
   "source": [
    "Choose a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adbe3cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gemini-2.0-flash"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $model = \"gemini-2.0-flash\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fdce8",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53047d",
   "metadata": {},
   "source": [
    "### Define a local function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82d074",
   "metadata": {},
   "source": [
    "Define a few subs -- _tools_ -- with sub- and argument descriptions (i.e. attached Pod values, or [declarator blocks](https://docs.raku.org/language/pod#Declarator_blocks)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5eda70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "&dim-lights-impl"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| Powers the spinning disco ball.\n",
    "sub power-disco-ball-impl(\n",
    "    Int:D $power #= Whether to turn the disco ball on or off.\n",
    "    ) returns Hash {\n",
    "    return { status => \"Disco ball powered \" ~ ($power ?? 'on' !! 'off') };\n",
    "}\n",
    "#= A status dictionary indicating the current state.\n",
    "\n",
    "#| Play some music matching the specified parameters.\n",
    "sub start-music-impl(\n",
    "    Int:D $energetic, #=  Whether the music is energetic or not.\n",
    "    Int:D $loud       #= Whether the music is loud or not.\n",
    "    ) returns Hash {\n",
    "    my $music-type = $energetic ?? 'energetic' !! 'chill';\n",
    "    my $volume = $loud ?? 'loud' !! 'quiet';\n",
    "    return { music_type => $music-type, volume => $volume };\n",
    "    #= A dictionary containing the music settings.\n",
    "}\n",
    "\n",
    "#| Dim the lights.\n",
    "sub dim-lights-impl(\n",
    "    Numeric:D $brightness #= The brightness of the lights, 0.0 is off, 1.0 is full.\n",
    "    ) returns Hash {\n",
    "    return { brightness => $brightness };\n",
    "}\n",
    "#= A dictionary containing the new brightness setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004df8ec",
   "metadata": {},
   "source": [
    "**Remark:** See the corresponding Python definitions in the section [\"Parallel Function Calling\"](https://ai.google.dev/gemini-api/docs/function-calling#parallel_function_calling) of [Gem1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20e507",
   "metadata": {},
   "source": [
    "The sub `llm-tool-definition` can be used to _automatically_ generate the Raku-hashmaps or JSON-strings of the tool descriptors in the (somewhat universal) format required by LLMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06bac237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"type\": \"function\",\n",
       "  \"function\": {\n",
       "    \"parameters\": {\n",
       "      \"type\": \"object\",\n",
       "      \"properties\": {\n",
       "        \"$brightness\": {\n",
       "          \"type\": \"number\",\n",
       "          \"description\": \"The brightness of the lights, 0.0 is off, 1.0 is full.\"\n",
       "        }\n",
       "      },\n",
       "      \"required\": [\n",
       "        \"$brightness\"\n",
       "      ],\n",
       "      \"additionalProperties\": false\n",
       "    },\n",
       "    \"description\": \"Dim the lights.\",\n",
       "    \"type\": \"function\",\n",
       "    \"strict\": true,\n",
       "    \"name\": \"dim-lights-impl\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm-tool-definition(&dim-lights-impl, format => 'json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6671ada",
   "metadata": {},
   "source": [
    "**Remark:** The sub `llm-tool-description` is invoked in `LLM::Tool.new`. Hence (ideally) `llm-tool-description` would not be user-invoked that often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a68f7",
   "metadata": {},
   "source": [
    "These are the tool descriptions to be communicated to Gemini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d46901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector(Struct([description, name, parameters], [Str, Str, Hash]), 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @tools =\n",
    "{\n",
    "    :name(\"power-disco-ball-impl\"), \n",
    "    :description(\"Powers the spinning disco ball.\"), \n",
    "    :parameters(\n",
    "        {\n",
    "            :type(\"object\")\n",
    "            :properties( {\"\\$power\" => {:description(\"Whether to turn the disco ball on or off.\"), :type(\"integer\")}}), \n",
    "            :required([\"\\$power\"]), \n",
    "        }), \n",
    "},\n",
    "{\n",
    "    :name(\"start-music-impl\"), \n",
    "    :description(\"Play some music matching the specified parameters.\"), \n",
    "    :parameters(\n",
    "        {\n",
    "            :type(\"object\")\n",
    "            :properties({\n",
    "                \"\\$energetic\" => {:description(\"Whether the music is energetic or not.\"), :type(\"integer\")}, \n",
    "                \"\\$loud\" => {:description(\"Whether the music is loud or not.\"), :type(\"integer\")}\n",
    "            }), \n",
    "            :required([\"\\$energetic\", \"\\$loud\"]), \n",
    "        }),\n",
    "},\n",
    "{\n",
    "    :name(\"dim-lights-impl\"), \n",
    "    :description(\"Dim the lights.\"), \n",
    "    :parameters(\n",
    "        {\n",
    "            :type(\"object\")\n",
    "            :properties({\"\\$brightness\" => {:description(\"The brightness of the lights, 0.0 is off, 1.0 is full.\"), :type(\"number\")}}), \n",
    "            :required([\"\\$brightness\"]), \n",
    "        }), \n",
    "};\n",
    "\n",
    "deduce-type(@tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802e12e",
   "metadata": {},
   "source": [
    "Here are additional tool-mode configurations (see [\"Function calling modes\"](https://ai.google.dev/gemini-api/docs/function-calling?example=weather#function_calling_modes) of [Gem1]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e861ccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{functionCallingConfig => {allowedFunctionNames => (power-disco-ball-impl start-music-impl dim-lights-impl), mode => ANY}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my %toolConfig =\n",
    "  functionCallingConfig => {\n",
    "    mode => \"ANY\",\n",
    "    allowedFunctionNames => <power-disco-ball-impl start-music-impl dim-lights-impl>\n",
    "  };"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08feac",
   "metadata": {},
   "source": [
    "### First communication with Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f7765",
   "metadata": {},
   "source": [
    "Initialize messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90341438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{parts => [text => Turn this place into a party!], role => user}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User prompt\n",
    "my $prompt = 'Turn this place into a party!';\n",
    "\n",
    "# Prepare the API request payload\n",
    "my @messages = [{role => 'user',parts => [ %( text => $prompt ) ]}, ];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85dda7f",
   "metadata": {},
   "source": [
    "Send the first chat completion request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc2cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my $response = gemini-generate-content(\n",
    "    @messages,\n",
    "    :$model,\n",
    "    :@tools,\n",
    "    :%toolConfig\n",
    ");\n",
    "\n",
    "deduce-type($response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a05f7857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Struct([candidates, modelVersion, responseId, usageMetadata], [Hash, Str, Str, Hash])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduce-type($response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bf258",
   "metadata": {},
   "source": [
    "The response is already parsed from JSON to Raku. Here is its JSON form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "333b1915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"modelVersion\": \"gemini-2.0-flash\",\n",
       "  \"candidates\": [\n",
       "    {\n",
       "      \"content\": {\n",
       "        \"role\": \"model\",\n",
       "        \"parts\": [\n",
       "          {\n",
       "            \"functionCall\": {\n",
       "              \"name\": \"start-music-impl\",\n",
       "              \"args\": {\n",
       "                \"$loud\": 1,\n",
       "                \"$energetic\": 1\n",
       "              }\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"functionCall\": {\n",
       "              \"args\": {\n",
       "                \"$power\": 1\n",
       "              },\n",
       "              \"name\": \"power-disco-ball-impl\"\n",
       "            }\n",
       "          },\n",
       "          {\n",
       "            \"functionCall\": {\n",
       "              \"args\": {\n",
       "                \"$brightness\": 0.5\n",
       "              },\n",
       "              \"name\": \"dim-lights-impl\"\n",
       "            }\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"safetyRatings\": [\n",
       "        {\n",
       "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "          \"probability\": \"NEGLIGIBLE\"\n",
       "        },\n",
       "        {\n",
       "          \"probability\": \"NEGLIGIBLE\",\n",
       "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\"\n",
       "        },\n",
       "        {\n",
       "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "          \"probability\": \"NEGLIGIBLE\"\n",
       "        },\n",
       "        {\n",
       "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "          \"probability\": \"NEGLIGIBLE\"\n",
       "        }\n",
       "      ],\n",
       "      \"avgLogprobs\": -0.0012976408004760742,\n",
       "      \"finishReason\": \"STOP\"\n",
       "    }\n",
       "  ],\n",
       "  \"responseId\": \"CgFFaOybFtWTmecPuOXGmAg\",\n",
       "  \"usageMetadata\": {\n",
       "    \"totalTokenCount\": 143,\n",
       "    \"candidatesTokenCount\": 30,\n",
       "    \"promptTokensDetails\": [\n",
       "      {\n",
       "        \"tokenCount\": 113,\n",
       "        \"modality\": \"TEXT\"\n",
       "      }\n",
       "    ],\n",
       "    \"candidatesTokensDetails\": [\n",
       "      {\n",
       "        \"tokenCount\": 30,\n",
       "        \"modality\": \"TEXT\"\n",
       "      }\n",
       "    ],\n",
       "    \"promptTokenCount\": 113\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to-json($response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfeaf5",
   "metadata": {},
   "source": [
    "### Refine the response with functional calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da300ea",
   "metadata": {},
   "source": [
    "The following copy of the messages is not required, but it makes repeated experiments easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51dc294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{parts => [text => Turn this place into a party!], role => user}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @messages2 = @messages;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8baf377",
   "metadata": {},
   "source": [
    "Let us define an `LLM::Tool` object for each tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29627b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMTool(power-disco-ball-impl, Powers the spinning disco ball.)\n",
      "LLMTool(start-music-impl, Play some music matching the specified parameters.)\n",
      "LLMTool(dim-lights-impl, Dim the lights.)\n"
     ]
    }
   ],
   "source": [
    "my @toolObjects = [&power-disco-ball-impl, &start-music-impl, &dim-lights-impl].map({ LLM::Tool.new($_) });\n",
    "\n",
    ".say for @toolObjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc7421",
   "metadata": {},
   "source": [
    "Make an `LLM::Request` object for each request from the (first) LLM response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c59f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMToolRequest(start-music-impl, :$loud(1), :$energetic(1), :id(Whatever))\n",
      "LLMToolRequest(power-disco-ball-impl, :$power(1), :id(Whatever))\n",
      "LLMToolRequest(dim-lights-impl, :$brightness(0.5), :id(Whatever))\n"
     ]
    }
   ],
   "source": [
    "my @requestObjects = $response<candidates>»<content>»<parts>.&flatten»<functionCall>.map({ LLM::ToolRequest.new( $_<name>, $_<args>) });\n",
    "\n",
    ".say for @requestObjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e35b7",
   "metadata": {},
   "source": [
    "Using the relevant tool for each request compute tool's response (which are `LLM::ToolResponse` objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a03ac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{music_type => energetic, volume => loud}\n",
      "{status => Disco ball powered on}\n",
      "{brightness => 0.5}\n"
     ]
    }
   ],
   "source": [
    ".say for @requestObjects.map({ generate-llm-tool-response(@toolObjects, $_) })».output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f231e",
   "metadata": {},
   "source": [
    "Alternatively, the `LLM::ToolResponse` objects can be converted into hashmaps structured according a particular LLM function calling style (Gemini in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7f86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{functionResponse => {name => start-music-impl, response => {content => {music_type => energetic, volume => loud}}}}\n",
      "{functionResponse => {name => power-disco-ball-impl, response => {content => {status => Disco ball powered on}}}}\n",
      "{functionResponse => {name => dim-lights-impl, response => {content => {brightness => 0.5}}}}\n"
     ]
    }
   ],
   "source": [
    ".say for @requestObjects.map({ generate-llm-tool-response(@toolObjects, $_) })».Hash('Gemini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6f835",
   "metadata": {},
   "source": [
    "Process the response:\n",
    "- Make a request object for each function call request\n",
    "- Compute the tool results\n",
    "- Form corresponding user message with those results\n",
    "- Send the messages to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64737cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Alright! I've started some energetic and loud music, turned on the disco ball, and dimmed the lights to 50% brightness. Let's get this party started!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my $assistant-message = $response<candidates>[0]<content>;\n",
    "if $assistant-message<parts> {\n",
    "\n",
    "    # Find function call parts and make corresponding tool objects\n",
    "    my @requestObjects;\n",
    "    for |$assistant-message<parts> -> %part {\n",
    "        if %part<functionCall> {\n",
    "            @requestObjects.push: LLM::ToolRequest.new( %part<functionCall><name>, %part<functionCall><args> ) \n",
    "        }\n",
    "    }    \n",
    "\n",
    "    # Add assistance message\n",
    "    @messages2.push($assistant-message);\n",
    "\n",
    "    # Compute tool responses\n",
    "    my @funcParts = @requestObjects.map({ generate-llm-tool-response(@toolObjects, $_) })».Hash('Gemini');\n",
    "\n",
    "    # Make and add the user response\n",
    "    my %function-response =\n",
    "        role => 'user',\n",
    "        parts => @funcParts;\n",
    "\n",
    "    @messages2.push(%function-response);\n",
    "                \n",
    "    # Send the second request with function result\n",
    "    my $final-response = gemini-generate-content(\n",
    "        @messages2,\n",
    "        :@tools,\n",
    "        :$model,\n",
    "        format => \"raku\"\n",
    "    );\n",
    "                \n",
    "    say \"Assistant: \", $final-response<candidates>[0]<content><parts>».<text>.join(\"\\n\");\n",
    "\n",
    "} else {\n",
    "    say \"Assistant: $assistant-message<content>\";\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b47fa",
   "metadata": {},
   "source": [
    "**Remark** Compared to the workflows in [AA1, AA2] the code above in simpler, more universal and robust, and handles all tool requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f45577",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdc98e",
   "metadata": {},
   "source": [
    "We can observe and conclude that LLM function calling workflows are greatly simplified by:\n",
    "\n",
    "- Leveraging Raku introspection\n",
    "    - This requires documenting the subs and their parameters.\n",
    "- Using dedicated classes that represent tool:\n",
    "    - Definitions, (`LLM::Tool`)\n",
    "    - Requests, (`LLM::ToolRequest`)\n",
    "    - Responses, (`LLM::ToolResponse`)\n",
    "- Having a sub (`generate-llm-tool-response`) that automatically matches request objects to tool objects and produces the corresponding response objects.\n",
    "    - Note the Gemini's documentation does not show that matching in the corresponding function calling example [\"Parallel Function Calling\"](https://ai.google.dev/gemini-api/docs/function-calling#parallel_function_calling).\n",
    "\n",
    "Raku's LLM tools automation is similar to Gemini's [\"Automatic Function Calling (Python Only)\"](https://ai.google.dev/gemini-api/docs/function-calling?example=weather#automatic_function_calling_python_only).\n",
    "\n",
    "The Wolfram Language LLM tooling functionalities are reflected in Raku's \"LLM::Tooling\", [WRI1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64325ea",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b3454",
   "metadata": {},
   "source": [
    "### Articles, blog posts\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"LLM function calling workflows (Part 1, OpenAI)\"](https://rakuforprediction.wordpress.com/2025/06/01/llm-function-calling-workflows-part-1-openai/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[AA2] Anton Antonov,\n",
    "[\"LLM function calling workflows (Part 2, Google's Gemini)\"](https://rakuforprediction.wordpress.com/2025/06/01/llm-function-calling-workflows-part-2-google-gemini/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[AA3] Anton Antonov,\n",
    "[\"LLM function calling workflows (Part 3, Facilitation)\"](https://rakuforprediction.wordpress.com/2025/06/01/llm-function-calling-workflows-part-30-facilitation/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[Gem1] Google Gemini,\n",
    "[\"Gemini Developer API\"](https://ai.google.dev/gemini-api/docs).\n",
    "\n",
    "[WRI1] Wolfram Research, Inc.\n",
    "[\"LLM-Related Functionality\" guide](https://reference.wolfram.com/language/guide/LLMFunctions.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c69c70",
   "metadata": {},
   "source": [
    "### Packages \n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[WWW::OpenAI Raku package](https://github.com/antononcube/Raku-WWW-OpenAI),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[WWW::Gemini Raku package](https://github.com/antononcube/Raku-WWW-Gemini),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
