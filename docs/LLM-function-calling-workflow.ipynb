{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f19be3f",
   "metadata": {},
   "source": [
    "# Using Gemini's Function Calling\n",
    "\n",
    "Anton Antonov   \n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com)   \n",
    "June 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db6a8c",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47dbde",
   "metadata": {},
   "source": [
    "This notebook shows how to do [Function Calling](https://ai.google.dev/gemini-api/docs/function-calling) workflows with Large Language Models (LLMs) of Gemini. \n",
    "\n",
    "The Raku package [\"WWW::Gemini\"](https://github.com/antononcube/Raku-WWW-Gemini), [AAp2], is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273a6d8",
   "metadata": {},
   "source": [
    "### Examples and big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0576c2",
   "metadata": {},
   "source": [
    "The rest of the notebook gives concrete code how to do function calling with Gemini's LLMs using Raku.\n",
    "\n",
    "There are [similar workflows](https://rakuforprediction.wordpress.com/2025/06/01/llm-function-calling-workflows-part-1-openai/), [AA1], with other LLM providers. (Like, OpenAI.) They follow the same structure, although there are some small differences. (Say, in the actual specifications of tools.)\n",
    "\n",
    "It would be nice to have:\n",
    "- Universal programming interface for those function calling interfaces.\n",
    "- Facilitation of tool descriptions derivations.\n",
    "    - Via Raku's introspection or using suitable LLM prompts.\n",
    "        - [\"LLM::Functions\"](https://raku.land/zef:antononcube/LLM::Functions), [AAp3], can be used for both approaches.\n",
    "\n",
    "This notebook belongs to a collection of notebooks describing how to do LLM function calling with Raku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bcc90a",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe460b7",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8afa369",
   "metadata": {},
   "outputs": [],
   "source": [
    "use WWW::Gemini;\n",
    "use JSON::Fast;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515092ec",
   "metadata": {},
   "source": [
    "Choose a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe3cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gemini-2.0-flash"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $model = \"gemini-2.0-flash\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559fdce8",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53047d",
   "metadata": {},
   "source": [
    "### Define a local function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82d074",
   "metadata": {},
   "source": [
    "This is the \"tool\" to be communicated to Gemini. (I.e. define the local function/sub.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5eda70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "&get-current-weather"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub get-current-weather(Str:D $location, Str:D $unit = \"fahrenheit\") returns Str {\n",
    "    return \"It is currently sunny in $location with a temperature of 72 degrees $unit.\";\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a68f7",
   "metadata": {},
   "source": [
    "Define the function specification (as prescribed in [Gemini's function calling documentation](https://ai.google.dev/gemini-api/docs/function-calling?example=weather)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d46901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{description => Get the current weather in a given location, name => get-current-weather, parameters => {properties => {location => {description => The city and state, e.g., Boston, MA, type => string}}, required => [location], type => object}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my %weather-function = %(\n",
    "    name => 'get-current-weather',\n",
    "    description => 'Get the current weather in a given location',\n",
    "    parameters => %(\n",
    "        type => 'object',\n",
    "        properties => %(\n",
    "            location => %(\n",
    "                type => 'string',\n",
    "                description => 'The city and state, e.g., Boston, MA'\n",
    "            )\n",
    "        ),\n",
    "        required => ['location']\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08feac",
   "metadata": {},
   "source": [
    "### First communication with Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113402e1",
   "metadata": {},
   "source": [
    "Initialize messages and tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90341438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{description => Get the current weather in a given location, name => get-current-weather, parameters => {properties => {location => {description => The city and state, e.g., Boston, MA, type => string}}, required => [location], type => object}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User prompt\n",
    "my $prompt = 'What is the weather like in Boston, MA, USA?';\n",
    "\n",
    "# Prepare the API request payload\n",
    "my @messages = [{role => 'user',parts => [ %( text => $prompt ) ]}, ];\n",
    "\n",
    "my @tools = [%weather-function, ];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ecd64",
   "metadata": {},
   "source": [
    "Send the first chat completion request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfc2cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{candidates => [{avgLogprobs => -8.74033301240868e-06, content => {parts => [{functionCall => {args => {location => Boston, MA}, name => get-current-weather}}], role => model}, finishReason => STOP, safetyRatings => [{category => HARM_CATEGORY_HATE_SPEECH, probability => NEGLIGIBLE} {category => HARM_CATEGORY_DANGEROUS_CONTENT, probability => NEGLIGIBLE} {category => HARM_CATEGORY_HARASSMENT, probability => NEGLIGIBLE} {category => HARM_CATEGORY_SEXUALLY_EXPLICIT, probability => NEGLIGIBLE}]}], modelVersion => gemini-2.0-flash, responseId => 1N1AaKL1IYKy7dcPpsXjqA0, usageMetadata => {candidatesTokenCount => 9, candidatesTokensDetails => [{modality => TEXT, tokenCount => 9}], promptTokenCount => 41, promptTokensDetails => [{modality => TEXT, tokenCount => 41}], totalTokenCount => 50}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $response = gemini-generate-content(\n",
    "    @messages,\n",
    "    :$model,\n",
    "    :@tools\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745bf258",
   "metadata": {},
   "source": [
    "The response is already parsed from JSON to Raku. Here is its JSON form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333b1915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"modelVersion\": \"gemini-2.0-flash\",\n",
       "  \"candidates\": [\n",
       "    {\n",
       "      \"safetyRatings\": [\n",
       "        {\n",
       "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "          \"probability\": \"NEGLIGIBLE\"\n",
       "        },\n",
       "        {\n",
       "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "          \"probability\": \"NEGLIGIBLE\"\n",
       "        },\n",
       "        {\n",
       "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "          \"probability\": \"NEGLIGIBLE\"\n",
       "        },\n",
       "        {\n",
       "          \"probability\": \"NEGLIGIBLE\",\n",
       "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\"\n",
       "        }\n",
       "      ],\n",
       "      \"finishReason\": \"STOP\",\n",
       "      \"content\": {\n",
       "        \"role\": \"model\",\n",
       "        \"parts\": [\n",
       "          {\n",
       "            \"functionCall\": {\n",
       "              \"args\": {\n",
       "                \"location\": \"Boston, MA\"\n",
       "              },\n",
       "              \"name\": \"get-current-weather\"\n",
       "            }\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"avgLogprobs\": -8.74033301240868e-06\n",
       "    }\n",
       "  ],\n",
       "  \"responseId\": \"1N1AaKL1IYKy7dcPpsXjqA0\",\n",
       "  \"usageMetadata\": {\n",
       "    \"promptTokenCount\": 41,\n",
       "    \"promptTokensDetails\": [\n",
       "      {\n",
       "        \"modality\": \"TEXT\",\n",
       "        \"tokenCount\": 41\n",
       "      }\n",
       "    ],\n",
       "    \"candidatesTokenCount\": 9,\n",
       "    \"totalTokenCount\": 50,\n",
       "    \"candidatesTokensDetails\": [\n",
       "      {\n",
       "        \"modality\": \"TEXT\",\n",
       "        \"tokenCount\": 9\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to-json($response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfeaf5",
   "metadata": {},
   "source": [
    "### Refine the response with functional calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363543f6",
   "metadata": {},
   "source": [
    "The following copy of the messages is not required, but it makes repeated experiments easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51dc294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{parts => [text => What is the weather like in Boston, MA, USA?], role => user}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @messages2 = @messages;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d5f17",
   "metadata": {},
   "source": [
    "Process the response -- invoke the tool, give the tool result to the LLM, get the LLM answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64737cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The weather in Boston, MA is currently sunny with a temperature of 72 degrees Fahrenheit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my $assistant-message = $response<candidates>[0]<content>;\n",
    "if $assistant-message<parts> {\n",
    "\n",
    "    for |$assistant-message<parts> -> %part {\n",
    "        if %part<functionCall> {\n",
    "            \n",
    "            @messages2.push($assistant-message);\n",
    "\n",
    "            my $func-name = %part<functionCall><name>;\n",
    "            my %args = %part<functionCall><args>;\n",
    "\n",
    "            \n",
    "            if $func-name eq 'get-current-weather' {\n",
    "                my $location = %args<location>;\n",
    "                my $weather = get-current-weather($location);\n",
    "\n",
    "                my %function-response =\n",
    "                            role => 'user',\n",
    "                            parts => [{ \n",
    "                                functionResponse => {\n",
    "                                    name => 'get-current-weather',\n",
    "                                    response => %( content => $weather )\n",
    "                                } \n",
    "                            }];\n",
    "\n",
    "                @messages2.push(%function-response);\n",
    "                \n",
    "                # Send the second request with function result\n",
    "                my $final-response = gemini-generate-content(\n",
    "                    @messages2,\n",
    "                    :@tools,\n",
    "                    :$model,\n",
    "                    format => \"raku\"\n",
    "                );\n",
    "                \n",
    "                say \"Assistant: \", $final-response<candidates>[0]<content><parts>».<text>.join(\"\\n\");\n",
    "\n",
    "                last\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "} else {\n",
    "    say \"Assistant: $assistant-message<content>\";\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831e02f",
   "metadata": {},
   "source": [
    "**Remark:** Note that if `get-current-weather` is applied then the loop above immediately finishes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7cd71d",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b939e",
   "metadata": {},
   "source": [
    "### Articles, blog posts\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"LLM function calling workflows (Part 1, OpenAI)\"](https://rakuforprediction.wordpress.com/2025/06/01/llm-function-calling-workflows-part-1-openai/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[AA2] Anton Antonov,\n",
    "[\"LLM function calling workflows (Part 2, Google's Gemini)\"](https://rakuforprediction.wordpress.com/2025/06/01/llm-function-calling-workflows-part-2-google-gemini/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b7e14f",
   "metadata": {},
   "source": [
    "### Packages \n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[WWW::OpenAI Raku package](https://github.com/antononcube/Raku-WWW-OpenAI),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[WWW::Gemini Raku package](https://github.com/antononcube/Raku-WWW-Gemini),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023-2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
